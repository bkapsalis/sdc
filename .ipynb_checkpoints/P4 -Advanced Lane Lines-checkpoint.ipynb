{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "\n",
    "The goals / steps of this project are the following:  \n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply the distortion correction to the raw image.  \n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\"). \n",
    "* Detect lane pixels and fit to find lane boundary.\n",
    "* Determine curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "Examples are give throughout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration Matrix and Distortion Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#%matplotlib qt\n",
    "\n",
    "def calibrate_lens(cal_imgs, nx, ny):\n",
    "    #3 of the 20 images in the test image file where not being read in with 9 by 6\n",
    "    #so the maximum posible dimensions where used.\n",
    "    nx=[5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6]\n",
    "    ny=[9,9,9,5,7,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9]\n",
    "\n",
    "    #Arrays to store object points and image points from all the images\n",
    "    objpoints = [] #3D points in real world space, all same 8by6by1 board\n",
    "    imgpoints = [] #2D points in image plane\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(cal_imgs)\n",
    "    \n",
    "    #images = sorted(images)\n",
    "    #print(images)\n",
    "\n",
    "    count = 0\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        \n",
    "        #Prepare object points, like (0,0,0),(1,0,0),(2,0,0)...,(7,5,0)\n",
    "        #objp = np.zeros((6*8,3), np.float32)\n",
    "        objp = np.zeros((ny[idx]*nx[idx],3), np.float32) \n",
    "        #objp[:,:2] = np.mgrid[0:8,0:6].T.reshape(-1,2) #x,y coordinates\n",
    "        objp[:,:2] = np.mgrid[0:nx[idx],0:ny[idx]].T.reshape(-1,2) #x,y coordinates        \n",
    "        #print(idx)\n",
    "        img = cv2.imread(fname)\n",
    "        #Grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Find Chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx[idx], ny[idx]), None)\n",
    "        #print( ret, corners)\n",
    "        #If found, draw corners\n",
    "        if ret== True:\n",
    "            count +=1\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            #Draw and display corners\n",
    "            #img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            #plt.imshow(img)\n",
    "            #cv2.waitKey(500)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #print(count, \"C\")\n",
    "    #print(count, len(objpoints), len(imgpoints))\n",
    "    \n",
    "    #return (cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None,None), count )    \n",
    "    return cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None,None) \n",
    "\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs =    calibrate_lens('camera_cal/calibration*.jpg', nx =9, ny =6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read and display the original images one at a time\n",
    "\n",
    "#image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "#image = mpimg.imread('test_images/solidYellowLeft.jpg')\n",
    "#image = mpimg.imread('test_images/test1.jpg')\n",
    "#image = mpimg.imread('test_images/test2.jpg')\n",
    "#image = mpimg.imread('test_images/test3.jpg')\n",
    "#image = mpimg.imread('test_images/test4.jpg')\n",
    "image = mpimg.imread('test_images/test5.jpg')\n",
    "#image = mpimg.imread('test_images/test6.jpg')\n",
    "#print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*')\n",
    "\n",
    "count = 0\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):                 \n",
    "    img = mpimg.imread(fname)\n",
    "    img_size = (img.shape[1], img.shape[0])                 \n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)             \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)  \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thresholded Binary Image\n",
    "Functions were written to get the high, med and low thresholds of RBG, HLS , Magnitude and Direction Gradients and create a binary images. An example of the visualization demonstrates that the high threshold for the S channel of HLS was one of the best for visualizing the lane lines in shadowy areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Threshold\n",
    "#Applying Sobel\n",
    "\n",
    "#Define a function that takes an image, gradient orientation,\n",
    "# and threshold min/ max values.\n",
    "#Scale the result to an 8-bit range (0-255)\n",
    "\n",
    "def abs_sobel_thresh(img, sobel_kernel = 3, orient = 'x', thresh = (0,255)):\n",
    "    #Grayscale\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #Apply x or y gradient with the OpenCV Sobel() function\n",
    "    #and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize= sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize= sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    #Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    #Return the binary image\n",
    "    return binary_output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Magnitude of the Gradient\n",
    "\n",
    "#Define a function to return  the magnitude of the gradient\n",
    "#for a given sobel kernel size  and  threshold values\n",
    "#Test that your function returns output similar to the example below for sobel_kernel=9, mag_thresh=(30, 100).\n",
    "#image lesson 20 \n",
    "def mag_thresh(img, sobel_kernel = 3,x_or_y_or_xy= 'xy', mag_thresh = (0,255)):\n",
    "    #Grayscale\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize= sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize= sobel_kernel)\n",
    "    #Calculate the gradient magnitude\n",
    "    if (x_or_y_or_xy == 'xy'):\n",
    "        gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    elif(x_or_y_or_xy == 'x'):\n",
    "        gradmag = np.sqrt(sobelx**2 )\n",
    "    else:\n",
    "        gradmag = np.sqrt( sobely**2)\n",
    "    #Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    #Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    #Return the binary image\n",
    "    return binary_output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Direction of the Gradient\n",
    "\n",
    "#The direction of the gradient is simply the arctangent of the \n",
    "#y-gradient divided by the x-gradient. tan^−1 (sobel y /sobel x ).\n",
    "#Each pixel of the resulting image contains a value for the angle of the \n",
    "#gradient away from horizontal in units of radians, \n",
    "#covering a range of −π/2 to π/2. An orientation of 0 implies \n",
    "#a horizontal line and orientations of +/−π/2 imply vertical lines.\n",
    "\n",
    "#Define a function to threshold an image for a given range and Sobel kernal\n",
    "def dir_threshold(img, sobel_kernel = 9, thresh=(0, np.pi/2)):\n",
    "    #Grayscale\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize= sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize= sobel_kernel)\n",
    "    #Take the absolute value of the gradient direction,\n",
    "    #apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    #Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a function that thresholds the S-channel of HLS\n",
    "\n",
    "def HLS_select(img, thresh=(174,255), H_or_L_or_S='S', Binary = False):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h = hls[:,:,0]\n",
    "    l = hls[:,:,1]\n",
    "    s = hls[:,:,2]\n",
    "\n",
    "    binary_output = np.zeros_like(s)\n",
    "\n",
    "    if H_or_L_or_S == 'H':\n",
    "        if Binary:\n",
    "            binary_output[(h > thresh[0]) & (h <= thresh[1])] = 1  \n",
    "            return binary_output\n",
    "        else:\n",
    "            return h\n",
    "    elif(H_or_L_or_S=='L'):\n",
    "        if Binary:\n",
    "            binary_output[(l > thresh[0]) & (l <= thresh[1])] = 1  \n",
    "            return binary_output \n",
    "        else:\n",
    "            return l\n",
    "    elif(H_or_L_or_S=='S'):\n",
    "        if Binary:\n",
    "            binary_output[(s > thresh[0]) & (s <= thresh[1])] = 1  \n",
    "            return binary_output\n",
    "        else:\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(images):                 \n",
    "    image = mpimg.imread(fname)\n",
    "    HLS_h_low = HLS_select(image, thresh=(0,90), H_or_L_or_S= 'H', Binary = True)\n",
    "    HLS_h_med = HLS_select(image, thresh=(90, 180), H_or_L_or_S= 'H', Binary = True)\n",
    "    HLS_h_high = HLS_select(image, thresh=(174, 255), H_or_L_or_S= 'H', Binary = True)\n",
    "    HLS_l_low = HLS_select(image, thresh=(0, 90),  H_or_L_or_S='L', Binary = True)\n",
    "    HLS_l_med = HLS_select(image, thresh=(90, 180),  H_or_L_or_S='L', Binary = True)\n",
    "    HLS_l_high = HLS_select(image, thresh=(174,255),  H_or_L_or_S='L', Binary = True)\n",
    "    HLS_s_low = HLS_select(image, thresh=(0, 90),  H_or_L_or_S='S', Binary = True)\n",
    "    HLS_s_med = HLS_select(image, thresh=(90, 180),  H_or_L_or_S='S', Binary = True)\n",
    "    HLS_s_high = HLS_select(image, thresh=(174, 255),  H_or_L_or_S='S', Binary = True)\n",
    "    \n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4 , figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Oringinal Image', fontsize=20)\n",
    " \n",
    "    ax2.imshow(HLS_s_high, cmap= 'gray')\n",
    "    ax2.set_title(' S_high', fontsize=20)      \n",
    "    ax3.imshow(HLS_s_med, cmap= 'gray')\n",
    "    ax3.set_title(' S_med', fontsize=20)      \n",
    "    ax4.imshow(HLS_s_low, cmap= 'gray')\n",
    "    ax4.set_title(' S_low', fontsize=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a function that thresholds RGB\n",
    "def RGB_select(img, thresh=(0,255), R_or_G_or_B = 'R', Binary = False):\n",
    "    #hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]   \n",
    "    b = img[:,:,2] \n",
    "    \n",
    "    binary_output = np.zeros_like(r)   \n",
    "    if R_or_G_or_B == 'R':\n",
    "        if Binary:\n",
    "            binary_output[(r > thresh[0]) & (r <= thresh[1])] = 1 \n",
    "            return binary_output\n",
    "        else:\n",
    "            return  r\n",
    "    elif(R_or_G_or_B=='G'):\n",
    "        if Binary:        \n",
    "            binary_output[(g > thresh[0]) & (g <= thresh[1])] = 1 \n",
    "            return binary_output\n",
    "        else:\n",
    "            return  g  \n",
    "    else:\n",
    "        if Binary:\n",
    "            binary_output[(b > thresh[0]) & (b <= thresh[1])] = 1  \n",
    "            return binary_output\n",
    "        else:\n",
    "            return  b     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Combining Thresholds\n",
    "\n",
    "Many combinations were tried to best visualize the lane lines. A final combination included S channel with a high threshold, gradient in the x direction with a low threshold, magnitude and directional gradients. Masking was used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipeline in process_image\n",
    "def pipeline(image_p):\n",
    "    #image = np.copy(image_p)\n",
    "\n",
    "    hls = cv2.cvtColor(image_p, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    #b = image_p[:,:,2]    \n",
    "    #Grayscale\n",
    "    gray= cv2.cvtColor(image_p, cv2.COLOR_RGB2GRAY)   \n",
    "    #Sobel x\n",
    "    #r_binary_high=  RGB_select(image_p, thresh=(170,255), R_or_G_or_B = 'R', Binary = True)\n",
    "    s_binary =    HLS_select(image_p, thresh=(174, 255),  H_or_L_or_S='S', Binary = True)\n",
    "    ksize = 9 # Choose a larger odd number to smooth gradient measurements\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image_p, sobel_kernel=ksize, orient='x', thresh=(10, 150))#20,100#Range 0 to 255 \n",
    "    #black with and without dstack single image ok without stack black with\n",
    "    ####grady = abs_sobel_thresh(image_p, sobel_kernel=ksize, orient='y', thresh=(50, 200))#Range 0 to 255 \n",
    "    #black with stack single, nonstack and stack#single image ok without stack black \n",
    "    mag_binary = mag_thresh(image_p, sobel_kernel=ksize, mag_thresh=(20,70))#(30,130))#(100,250))#70,250#30,100#Range 0 to 254 \n",
    "    #black stacked not stacked image\n",
    "    dir_binary = dir_threshold(image_p, sobel_kernel=ksize, thresh=(0.8, 1.05))#Range 0 to 1.6(pi/2)about\n",
    "    \n",
    "    #print(retval)\n",
    "    #print(sxbinary.shape,sxbinary )\n",
    "    #print(s_binary.shape,s_binary)\n",
    "    #print(gradx.shape,gradx)\n",
    "    #print(grady.shape,grady)\n",
    "    #print(mag_binary.shape,mag_binary[50][200:500],type(mag_binary))\n",
    "    #print(dir_binary.shape,dir_binary[50][200:500],type(dir_binary))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    #combined_binary = np.zeros_like(sxbinary)\n",
    "    #combined_binary[(s_binary == 255) | (sxbinary == 255)] = 1\n",
    "    #combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    #combined[(gradx == 1)  | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    #combined[(gradx == 1)  | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    #combined[(gradx == 1)  & ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined[(gradx == 1)  & ((mag_binary == 1) & (dir_binary == 1)) | (s_binary==1)] = 1\n",
    "    #combined[(gradx == 1)  & ((mag_binary == 1) & (dir_binary == 1)) | (s_binary==1)& (r_binary_high==1)] = 1\n",
    "    #add s \n",
    "    #remove y\n",
    "    #add b low\n",
    "    #dstack =np.dstack((s_binary,s_binary,s_binary))#!!!!!!CHANGE!!!!!!CHANGE!!!!!!\n",
    "    #dstack =np.dstack((mag_binary,mag_binary,mag_binary))#!!!!!!CHANGE!!!!!!CHANGE!!!!!!\n",
    "    #dstack =np.dstack((combined,combined,combined))#!!!!!!CHANGE!!!!!!CHANGE!!!!!!\n",
    "    \n",
    "    #return mag_binary\n",
    "    #return gradx\n",
    "    #return   s_binary\n",
    "    #return   dstack\n",
    "    return   combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pipeline(image)\n",
    "result_stack =np.dstack((result, result, result))\n",
    "\n",
    "#Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Oringinal Image', fontsize=50)\n",
    "ax2.imshow(result_stack, cmap= 'gray')\n",
    "ax2.set_title('Pipeline Result', fontsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undist = cv2.undistort(image, mtx, dist, None, mtx)  \n",
    "\n",
    "# 3-color and gradient threshold\n",
    "binary = pipeline(undist)\n",
    "img_shape=binary.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_min = 0\n",
    "y_min = 0\n",
    "x_max = img_shape[1]\n",
    "y_max = img_shape[0]\n",
    "\n",
    "top_right = [x_max*0.585, y_max*0.64]\n",
    "bottom_right = [x_max-0, y_max]\n",
    "bottom_left = [x_min+55, y_max]\n",
    "top_left = [x_max*0.425, y_max*0.64]\n",
    "\n",
    "offset = 100 # offset for dst points\n",
    "# Grab the image shape\n",
    "#img_size = (undist.shape[1], undist.shape[0])\n",
    "\n",
    "# For source points I'm grabbing the outer four detected corners\n",
    "src = np.float32([top_left, top_right, bottom_right, bottom_left])\n",
    "# For destination points, I'm arbitrarily choosing some points to be\n",
    "# a nice fit for displaying our warped result \n",
    "dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                 [img_size[0]-offset, img_size[1]-offset], \n",
    "                                 [offset, img_size[1]-offset]])\n",
    "\n",
    "vertices = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#    vertices = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)\n",
    "masked_edges = region_of_interest(binary, vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Oringinal Image', fontsize=50)\n",
    "ax2.imshow(masked_edges, cmap= 'gray')\n",
    "ax2.set_title('Masked Pipeline Result', fontsize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform (\"birds-eye view\")\n",
    "It will be easier to work with the binary lane line images if we had a bird eye view. The cv2.getPerspectiveTransform() was use to write a birds_eye() function to transform the lane line image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "#def corners_unwarp(img, mtx, dist):\n",
    "#def corners_unwarp(img): \n",
    "\n",
    "def birds_eye(undist, src, dst):    \n",
    "    #img_shape =image.shape\n",
    "    img_shape =undist.shape    \n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M,(img_shape[1],img_shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*')\n",
    "\n",
    "# Step through the list \n",
    "for idx, fname in enumerate(images[2:]):                 \n",
    "    image = mpimg.imread(fname)\n",
    "    img_shape =image.shape\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = img_shape[1]\n",
    "    y_max = img_shape[0]\n",
    "    top_right = [x_max*0.585, y_max*0.64]\n",
    "    bottom_right = [x_max-0, y_max]\n",
    "    bottom_left = [x_min+55, y_max]\n",
    "    top_left = [x_max*0.425, y_max*0.64]    \n",
    "    img_size = (image.shape[1], image.shape[0]) \n",
    "    vertices = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)\n",
    "#    top_down, perspective_M = corners_unwarp(image,mtx, dist)  \n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    top_down, perspective_M = birds_eye(undist, src, dst)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize = (24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.plot(top_right[0], top_right[1], '.')#top right blue\n",
    "    ax1.plot(bottom_right[0], bottom_right[1], '.')#bottom right green\n",
    "    ax1.plot(bottom_left[0], bottom_left[1], '.')#bottom left red\n",
    "    ax1.plot(top_left[0], top_left[1], '.')#top left light green\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Undistorted and Wraped Image', fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#birds eye to transformed back to street\n",
    "def birds_to_street(undist, src,dst):    \n",
    "    #img_shape =image.shape\n",
    "    img_shape =undist.shape \n",
    "    #print(img_shape)\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    Minv = cv2.getPerspectiveTransform( dst, src)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    unwarped = cv2.warpPerspective(undist, Minv,(img_shape[1],img_shape[0]) , flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return unwarped, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels \n",
    "A Line class and a sliding window were used to find the lane line pixels. A histogram of the sum of the number of the pixels, in the lower half of the image, in each x positions was used to find the highest number of pixels and therefor the probable location of the starting point of the lane lines. Two histograms were used, one for the right half of the image and one for the left half. To save processing time two smaller windows were placed over the determined start points of each lane line. x and y postilions were recoded for each pixels in each row of the small windows. The average of the x postilions were used the calculate the next starting point of the next window. This resulted in the recording of x and y positions in a left or right Line class object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?                    CHECK?\n",
    "        self.detected = False                                       \n",
    "        #The initial peak of the histogram on the full x range.           CHECK\n",
    "        self.initial_peak= None                                            \n",
    "        # x values of the last n fits of the line                        CHECK\n",
    "        self.recent_xfitted = []\n",
    "        #average x values of the fitted line over the last n iterations   CHECK\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations     CHECK\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit                  CHECK \n",
    "        self.current_fit = [np.array([False])]  \n",
    " \n",
    "        #radius of curvature of the line in some units                  CHECK\n",
    "        self.radius_of_curvature = None                                    \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits        CHECK\n",
    "        #self.diffs = np.array([0,0,0], dtype='float') \n",
    "        self.diffs =[]\n",
    "        self.diffs_all =[]\n",
    "        self.diffs_l_r=[]\n",
    "        self.diffs_l_r_all=[]\n",
    "        #x values for detected line pixels                              CHECK\n",
    "        self.allx = []              \n",
    "        #y values for detected line pixels                                CHECK\n",
    "        self.ally = []\n",
    "        \n",
    "        # polynomial coefficients values of the last n fits of the line    New CHECK\n",
    "        self.recent_fit=[]\n",
    "        self.all_fit=[]\n",
    "        \n",
    "        self.recent_yvals_l = []\n",
    "        self.recent_yvals_r = []\n",
    "        #find the camera offset from center of car\n",
    "        self.diff_sum = 0\n",
    "        self.left_avg = 0\n",
    "        self.right_avg = 0\n",
    "        \n",
    "        self.left_fit_NOT_3 = 0\n",
    "        self.left_fitx_NOT_gt_100 = 0\n",
    "        \n",
    "        self.lane_center_pixels_recent_n = []\n",
    "        self.diff_from_center= []\n",
    "        self.counter_1 = 0\n",
    "        self.counter_2 = 0\n",
    "        self.counter_3 = 0\n",
    "        self.counter_4 = 0\n",
    "        self.counter_4a = 0\n",
    "        self.counter_5 = 0\n",
    "        self.counter_6 = 0\n",
    "        self.counter_7 = 0\n",
    "        self.counter_8 = 0\n",
    "        self.counter_9 = 0\n",
    "        self.counter_9a = 0\n",
    "        self.counter_10 = 0        \n",
    "        self.ratio_A = []\n",
    "        self.ratio_B = []       \n",
    "        self.ratio_C = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do this first before video\n",
    "l_line=Line()\n",
    "r_line=Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sliding_window to find lane line pixel locations\n",
    "def sliding_window(img,n):  \n",
    "    l_line.allx=[]\n",
    "    l_line.ally=[]\n",
    "    r_line.allx=[]\n",
    "    r_line.ally=[]\n",
    "    #print ('start')\n",
    "    #print (l_line.allx)\n",
    "    #print (l_line.ally)\n",
    "    #print (r_line.allx)\n",
    "    #print (r_line.ally)  \n",
    "\n",
    "    img_shape=img.shape\n",
    "    #print(img_shape)\n",
    "\n",
    "    histogram = np.sum(img[img.shape[0]/2:,:], axis= 0)\n",
    "\n",
    "    #no lanes will start befor 100 or after 1175\n",
    "    #any pixels in these ranges would be noise and set to zero.\n",
    "    histogram[0:100]=0\n",
    "    histogram[1175:]=0\n",
    "    l_lane_x = False\n",
    "    r_lane_x = False\n",
    "    left_half = histogram[0:len(histogram)/2]\n",
    "    right_half = histogram[len(histogram)/2:]\n",
    "    l_line.initial_peak = np.argmax(left_half) \n",
    "    r_line.initial_peak = np.argmax(right_half)+len(histogram)/2\n",
    "    l_lane_x = l_line.initial_peak\n",
    "    r_lane_x = r_line.initial_peak    \n",
    "    l_x_values=[]  \n",
    "    r_x_values=[]\n",
    "    #sliding window-starting at the bottom and sliding up 10% each slide\n",
    "    for i in range(0, 10):\n",
    "        #histogram = np.sum(img[img.shape[0]/2:,:], axis= 0)\n",
    "        window_bottom= img_shape[0]-(img_shape[0]*0.1* i)\n",
    "        window_top= img_shape[0]-(img_shape[0]*0.1*(i+1))          \n",
    "        window_l = img[window_top:window_bottom,(l_lane_x-100):(l_lane_x+100)]   \n",
    "        window_r = img[window_top:window_bottom,(r_lane_x-100):(r_lane_x+100)]  \n",
    "        win_l_shape = window_l.shape\n",
    "        win_r_shape = window_r.shape\n",
    "        for j in range(0,  win_l_shape[0]):\n",
    "            #gets the index values of the pixels position for that one row of window_l\n",
    "            indexes_l = np.nonzero(window_l[j:j+1,:])[1]\n",
    "            indexes_l_offset = (indexes_l-100)+l_lane_x\n",
    "            l_x_values = np.append(l_x_values,indexes_l_offset)\n",
    "\n",
    "            #y value will be same for all xs in row.\n",
    "            #pixel_y_values=j+i*72\n",
    "            pixel_y_values=720-(i*72)+(j) #test       \n",
    "            num_x_values_in_row_l =len(indexes_l)\n",
    "            #need to add as many y values to .ally as the number of x values added to .allx\n",
    "            #how many x values\n",
    "            array_y_values_l = [pixel_y_values] * num_x_values_in_row_l \n",
    "            l_line.ally = np.append(l_line.ally, array_y_values_l)\n",
    "\n",
    "            #gets the index values of the pixels position for that one row of window_r        \n",
    "            indexes_r = np.nonzero(window_r[j:j+1,:])[1]\n",
    "            indexes_r_offset = (indexes_r-100)+r_lane_x\n",
    "            r_x_values = np.append(r_x_values,indexes_r_offset) \n",
    "\n",
    "            #y value will be same for all xs in row.     \n",
    "            num_x_values_in_row_r =len(indexes_r)\n",
    "            #need to add as many y values to .ally as the number of x values added to .allx\n",
    "            #how many x values\n",
    "            array_y_values_r = [pixel_y_values] * num_x_values_in_row_r\n",
    "            r_line.ally = np.append(r_line.ally, array_y_values_r)        \n",
    "\n",
    "        previous_l_center = l_lane_x\n",
    "        previous_r_center = r_lane_x\n",
    "        if len(l_x_values)==0:\n",
    "            l_lane_x = previous_l_center\n",
    "        else:    \n",
    "            # take the mean of all x values for this window\n",
    "            #these means will be used as the center of the next window up\n",
    "            #l_lane_x = (np.mean(l_x_values)-100) + previous_l_center\n",
    "            l_lane_x = (np.mean(l_x_values))       \n",
    "        if len(r_x_values) ==0:\n",
    "            r_lane_x = previous_r_center\n",
    "        else:\n",
    "            #r_lane_x = (np.mean(r_x_values)-100) + previous_r_center \n",
    "            r_lane_x = (np.mean(r_x_values))  \n",
    "\n",
    "        #take the x values from this window and appendt to self.allx\n",
    "        l_line.allx = np.append(l_line.allx, l_x_values)\n",
    "        r_line.allx = np.append(r_line.allx, r_x_values)\n",
    "        #start from an empty array to get all the x values of the next window.\n",
    "        num_of_xs_per_window_l =len(l_x_values)   \n",
    "        num_of_xs_per_window_r =len(r_x_values)\n",
    "        l_x_values=[]  \n",
    "        r_x_values=[] \n",
    "        \n",
    "        #store all l_line x values for last n fits in 'self.recent_xfitted'\n",
    "        #print(l_line.recent_xfitted, 'starting point l_line.recent_xfitted')\n",
    "        #print(r_line.recent_xfitted, 'starting point r_line.recent_xfitted')\n",
    "    return l_line, r_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Curvature of the Lane and Vehicle Position with Respect to Center\n",
    "### Warp the Detected Lane Boundaries Back Onto the Original Image\n",
    "\n",
    "A second order polynomial was fit to each line: f(y) = Ay^2 + By + C \n",
    "As discused in lesson 13 the resulting coeficients have the following meaning:\n",
    "* A gives you the curvature of the lane line \n",
    "* B gives you the heading or direction that the line is pointing\n",
    "* C gives you the position of the line based on how far away it is from the very left of an image (y = 0)\n",
    "\n",
    "I used a few methods to find the lane line boundaries. First if  the current value of A, B or C were very different form the average of the past n values then the new image values must be wrong and the current values were not used. For this I created a ratio of current values divided by the average of the previous n images.  Second if the left and right A, B or C values were very different the line was probably not a lane line and not used. Lastly I used distance the lane line is from the center of the lane and if the current difference were very different form the previous n values the current values were not used.\n",
    "\n",
    "The ranges of each factor were determined by collecting all results and getting the max, min and average. This gave me an idea were to set the cutoffs to remove data. With trial and error about 10 percent of values were excluded. Only results with noticeable positive changes were used. \n",
    "\n",
    "In the event a current image values were not used the average of the previous n values were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pixels_to_image(warped, undist, src, dst, n):\n",
    "    count_l_left_fitx = 0\n",
    "    count_r_right_fitx = 0\n",
    "    img_size = (warped.shape[1], warped.shape[0])   \n",
    "    yvals_l=l_line.ally\n",
    "    yvals_l=yvals_l[::-1]\n",
    "    yvals_r=r_line.ally\n",
    "    yvals_r=yvals_r[::-1]\n",
    "    leftx= l_line.allx\n",
    "    leftx = leftx[::-1]#Reverse to match top-to-bottom in y\n",
    "    rightx= r_line.allx\n",
    "    rightx = rightx[::-1]#Reverse to match top-to-bottom in y\n",
    "    previous_fit_l = l_line.current_fit[0]\n",
    "    previous_fit_r = r_line.current_fit[0]\n",
    "\n",
    "    ####Get coeficients and fit x values\n",
    "    ####\n",
    "    #Fit a second order polynomial to each real lane line\n",
    "    left_fit = np.polyfit(yvals_l, leftx, 2)       # !!!!!!left_fit = l_line.current_fitsave as back up \n",
    "    left_fitx = left_fit[0]*yvals_l**2 + left_fit[1]*yvals_l + left_fit[2]\n",
    "    \n",
    "    #Fit a second order polynomial to each real lane line\n",
    "    right_fit = np.polyfit(yvals_r, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals_r**2 + right_fit[1]*yvals_r + right_fit[2]\n",
    "    \n",
    "    \n",
    "    ####Find center of car relitive to center of lane  ###  \n",
    "    ####\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    #determine center of the lane. \n",
    "    left_line_baseX = left_fit[2]#As stated in lesson 12 this is the distance from the bottom(y=720) left(x=0) of the image to the left lane line in pixels.\n",
    "    left_line_baseMeters = left_line_baseX * xm_per_pix\n",
    "    right_line_baseX = right_fit[2]#same for the right lane line.  \n",
    "    right_line_baseMeters = right_line_baseX * xm_per_pix\n",
    "    lane_center_pixels = left_line_baseX+(0.5 *(right_line_baseX-left_line_baseX))#in pixels\n",
    "    #convert to meters\n",
    "    lane_center_meters = lane_center_pixels * xm_per_pix # pixels * meter/pixel = meter\n",
    "    car_center_pixels = (1280/2) +  43# 683 pixels from the bottom left of the image to the center of the car in pixels\n",
    "    #Convert to meters.\n",
    "    #meters from left of image\n",
    "    car_center_meters = car_center_pixels * xm_per_pix \n",
    "    #Car center with respect to lane center in meters\n",
    "    car_relative_position = lane_center_meters - car_center_meters\n",
    "    #print(car_relative_position, 'car_relative_position meters')\n",
    "    \n",
    "    ####Set recent_xfitted and bestx \n",
    "    ####\n",
    "    #recent_xfitted is x values of the last n fits of the line[[],[],....n]\n",
    "    if (len(l_line.recent_xfitted) <n):\n",
    "        l_line.recent_xfitted.append(left_fitx)\n",
    "        l_line.recent_yvals_l.append(yvals_l)#New Don't need ??\n",
    "    else:\n",
    "        l_line.recent_xfitted = l_line.recent_xfitted[1:]\n",
    "        l_line.recent_yvals_l = l_line.recent_yvals_l[1:]#New    Don't need ??     \n",
    "        l_line.recent_xfitted.append(left_fitx)\n",
    "        l_line.recent_yvals_l.append(yvals_l)#New\n",
    "    #store all r_line x values for last n fits in 'self.recent_xfitted'\n",
    "    if (len(r_line.recent_xfitted) <n):\n",
    "        r_line.recent_xfitted.append(right_fitx)\n",
    "        r_line.recent_yvals_r.append(yvals_r)#New\n",
    "    else:\n",
    "        r_line.recent_xfitted = r_line.recent_xfitted[1:]\n",
    "        r_line.recent_yvals_r = r_line.recent_yvals_r[1:]#New\n",
    "        r_line.recent_xfitted.append(right_fitx)\n",
    "        r_line.recent_yvals_r.append(yvals_r)\n",
    "    n_xfitted_l_concat =np.concatenate(l_line.recent_xfitted)\n",
    "    n_yvals_l_concat =np.concatenate(l_line.recent_yvals_l)\n",
    "    n_xfitted_r_concat =np.concatenate(r_line.recent_xfitted)        \n",
    "    n_yvals_r_concat =np.concatenate(r_line.recent_yvals_r)  \n",
    "    #bestx is average x values of the fitted line over the last n iterations\n",
    "    l_line.bestx =np.average(np.concatenate(l_line.recent_xfitted))\n",
    "    r_line.bestx =np.average(np.concatenate(r_line.recent_xfitted))\n",
    "\n",
    "    ####Set self.current_fit, self.recent_fit and self.best_fit   \n",
    "    ####\n",
    "    #previous_fit_l = l_line.current_fit #Above\n",
    "    #previous_fit_r = r_line.current_fit #Above\n",
    "    #self.current_fit is polynomial coefficients for the most recent fit\n",
    "    l_line.current_fit=left_fit\n",
    "    r_line.current_fit=right_fit\n",
    "    #print(l_line.current_fit,'l_line.current_fit')\n",
    "    #print(r_line.current_fit,'r_line.current_fit')\n",
    "    #print(,'')\n",
    "    #print(,'')\n",
    "    l_line.diffs = np.absolute(l_line.current_fit - previous_fit_l)\n",
    "    r_line.diffs = np.absolute(r_line.current_fit - previous_fit_r)\n",
    "    l_line.diffs_l_r = np.absolute(l_line.current_fit-r_line.current_fit)   \n",
    "    #self.current_fit = [0,0,0]     \n",
    "    l_line.diffs_all.append(l_line.diffs)\n",
    "    r_line.diffs_all.append(r_line.diffs)\n",
    "    l_line.diffs_l_r_all.append(l_line.diffs_l_r)\n",
    "\n",
    "    if (l_line.lane_center_pixels_recent_n != []):\n",
    "        #print(len(l_line.diff_from_center),'len(l_line.diff_from_center)')\n",
    "        l_diff_from_center_n_max =np.max(l_line.diff_from_center)\n",
    "        l_diff_from_center_n_average =np.average(l_line.diff_from_center)\n",
    "        l_diff_from_center_n_min=np.min(l_line.diff_from_center)    \n",
    "\n",
    "        #print(l_diff_from_center_n_max,'l_diff_from_center_n_max')\n",
    "        #print(l_diff_from_center_n_average,'l_diff_from_center_n_average')\n",
    "        #print(l_diff_from_center_n_min, 'l_diff_from_center_n_min') \n",
    "    if (r_line.lane_center_pixels_recent_n != []):\n",
    "        #print(len(r_line.diff_from_center),'len(r_line.diff_from_center)')\n",
    "        r_diff_from_center_n_max =np.max(r_line.diff_from_center)\n",
    "        r_diff_from_center_n_average =np.average(r_line.diff_from_center)\n",
    "        r_diff_from_center_n_min=np.min(r_line.diff_from_center)    \n",
    "        #print(r_diff_from_center_n_max,'r_diff_from_center_n_max')\n",
    "        #print(r_diff_from_center_n_average,'r_diff_from_center_n_average')\n",
    "        #print(r_diff_from_center_n_min, 'r_diff_from_center_n_min')        \n",
    "    if (len(l_line.recent_fit) >0):\n",
    "        l_line.counter_1+=1\n",
    "        n_fit_max =np.max( np.asarray(l_line.recent_fit), axis = 0) \n",
    "        n_fit_average =np.average(np.asarray(l_line.recent_fit), axis = 0) \n",
    "        n_fit_min=np.min(np.asarray(l_line.recent_fit), axis = 0)     \n",
    "        #print('A = curvature, B = heading or direction, C = position of the line based')\n",
    "        #print(n_fit_max, 'n_fit_max') \n",
    "        #print(n_fit_average, 'n_fit_average')\n",
    "        #print(n_fit_min, 'n_fit_min')\n",
    "        gt_n0=30\n",
    "        gt_n1=10\n",
    "        gt_n2=50\n",
    "        lt_n0=30\n",
    "        lt_n1=10\n",
    "        lt_n2=50\n",
    "        \n",
    "        gt_d0=0.00000001\n",
    "        gt_d1=0.001\n",
    "        gt_d2=595\n",
    "        lt_d0=0.0006\n",
    "        lt_d1=6\n",
    "        lt_d2=645  \n",
    "        \n",
    "        gt_d3= 240\n",
    "        lt_d3 = 490\n",
    "        \n",
    "        l_line.ratio_A.append(l_line.current_fit[0]/n_fit_average[0])\n",
    "        l_line.ratio_B.append(l_line.current_fit[1]/n_fit_average[1])\n",
    "        l_line.ratio_C.append(l_line.current_fit[2]/n_fit_average[2])\n",
    "\n",
    "        #print( l_line.ratio_A[-1] ,'l_line.ratio_A[-1] ')\n",
    "        l_lane_center_pixels_recent_n_average  = np.average(l_line.lane_center_pixels_recent_n)\n",
    "        l_diff = np.absolute(l_lane_center_pixels_recent_n_average - l_line.current_fit[2])\n",
    "        #if (True):   \n",
    "        #if ((l_diff < ( lt_d3)) and (l_diff > (gt_d3))):             \n",
    "        if ((l_line.diffs_l_r[0] < ( lt_d0)) and (l_line.diffs_l_r[0] > (gt_d0))) \\\n",
    "            and ((l_line.diffs_l_r[1] < ( lt_d1)) and (l_line.diffs_l_r[1] > (gt_d1))) \\\n",
    "            and ((l_line.ratio_A[-1] < ( lt_n0)) and (l_line.ratio_A[-1] > (-1.0*gt_n0))):\n",
    "            l_line.counter_2 +=1\n",
    "            if (len(l_line.recent_fit) <n):\n",
    "                l_line.recent_fit.append(l_line.current_fit)\n",
    "                l_line.lane_center_pixels_recent_n.append(lane_center_pixels)\n",
    "                l_lane_center_pixels_recent_n_max =np.max(l_line.lane_center_pixels_recent_n)\n",
    "                l_lane_center_pixels_recent_n_average =np.average(l_line.lane_center_pixels_recent_n)\n",
    "                l_lane_center_pixels_recent_n_min=np.min(l_line.lane_center_pixels_recent_n)    \n",
    "                #print(l_lane_center_pixels_recent_n_max,'l_lane_center_pixels_recent_n_max')\n",
    "                #print(l_lane_center_pixels_recent_n_average,'l_lane_center_pixels_recent_n_average')\n",
    "                #print(l_lane_center_pixels_recent_n_min, 'l_lane_center_pixels_recent_n_min')                \n",
    "                l_line_diff_from_n_recent_center = np.absolute(l_lane_center_pixels_recent_n_average - l_line.current_fit[2])\n",
    "                #print(l_line_diff_from_n_recent_center,'l_line_diff_from_n_recent_center')\n",
    "                l_line.diff_from_center.append(l_line_diff_from_n_recent_center)\n",
    "                l_line.counter_3+=1\n",
    "            else:\n",
    "                l_line.recent_fit = l_line.recent_fit[1:]\n",
    "                l_line.recent_fit.append(l_line.current_fit)\n",
    "                l_line.lane_center_pixels_recent_n = l_line.lane_center_pixels_recent_n[1:]\n",
    "                l_line.lane_center_pixels_recent_n.append(lane_center_pixels)\n",
    "                l_lane_center_pixels_recent_n_max =np.max(l_line.lane_center_pixels_recent_n)\n",
    "                l_lane_center_pixels_recent_n_average =np.average(l_line.lane_center_pixels_recent_n)\n",
    "                l_lane_center_pixels_recent_n_min=np.min(l_line.lane_center_pixels_recent_n)    \n",
    "                #print(l_lane_center_pixels_recent_n_max,'l_lane_center_pixels_recent_n_max')\n",
    "                #print(l_lane_center_pixels_recent_n_average,'l_lane_center_pixels_recent_n_average')\n",
    "                #print(l_lane_center_pixels_recent_n_min, 'l_lane_center_pixels_recent_n_min')                \n",
    "                l_line_diff_from_n_recent_center = np.absolute(l_lane_center_pixels_recent_n_average - l_line.current_fit[2])\n",
    "                #print(l_line_diff_from_n_recent_center,'l_line_diff_from_n_recent_center')\n",
    "                l_line.diff_from_center.append(l_line_diff_from_n_recent_center)                \n",
    "                l_line.counter_4+=1\n",
    "        else:\n",
    "            l_line.counter_4a +=1\n",
    "    else:\n",
    "        l_line.recent_fit.append(l_line.current_fit)\n",
    "        l_line.lane_center_pixels_recent_n.append(lane_center_pixels)\n",
    "        l_lane_center_pixels_recent_n_max =np.max(l_line.lane_center_pixels_recent_n)\n",
    "        l_lane_center_pixels_recent_n_average =np.average(l_line.lane_center_pixels_recent_n)\n",
    "        l_lane_center_pixels_recent_n_min=np.min(l_line.lane_center_pixels_recent_n)    \n",
    "        #print(l_lane_center_pixels_recent_n_max,'l_lane_center_pixels_recent_n_max')\n",
    "        #print(l_lane_center_pixels_recent_n_average,'l_lane_center_pixels_recent_n_average')\n",
    "        #print(l_lane_center_pixels_recent_n_min, 'l_lane_center_pixels_recent_n_min')        \n",
    "        l_line_diff_from_n_recent_center = np.absolute(l_lane_center_pixels_recent_n_average - l_line.current_fit[2])\n",
    "        #print(l_line_diff_from_n_recent_center,'l_line_diff_from_n_recent_center')\n",
    "        l_line.diff_from_center.append(l_line_diff_from_n_recent_center)\n",
    "        l_line.counter_5+=1\n",
    "        \n",
    "    if (len(r_line.recent_fit) >0):\n",
    "        l_line.counter_6+=1\n",
    "        n_fit_max =np.max(np.asarray(r_line.recent_fit), axis = 0) \n",
    "        n_fit_average =np.average(np.asarray(r_line.recent_fit), axis = 0) \n",
    "        n_fit_min=np.min(np.asarray(r_line.recent_fit), axis = 0)     \n",
    "        #print('A = curvature, B = heading or direction, C = position of the line based')\n",
    "        #print(n_fit_max, 'n_fit_max') \n",
    "        #print(n_fit_average, 'n_fit_average')\n",
    "        #print(n_fit_min, 'n_fit_min')\n",
    "        nt=0.1\n",
    "        gt_n0=20\n",
    "        gt_n1=9\n",
    "        gt_n2=50\n",
    "        lt_n0=20\n",
    "        lt_n1=9\n",
    "        lt_n2=50\n",
    "\n",
    "        #self.recent_fit is polynomial coefficients values of the last n fits of the line\n",
    "        #Save n most recent fits if good fits.\n",
    "        #if the current A coefficients is with in a percentage of n recent A coefficents average\n",
    "        #& if the current B coefficients is with in a percentage of n recent B coefficents average\n",
    "        #& if the current C coefficients is with in a percentage of n recent C coefficents average\n",
    "        r_line.ratio_A.append(r_line.current_fit[0]/n_fit_average[0])\n",
    "        r_line.ratio_B.append(r_line.current_fit[1]/n_fit_average[1])\n",
    "        r_line.ratio_C.append(r_line.current_fit[2]/n_fit_average[2])\n",
    "        ratio_A_max =np.max(r_line.ratio_A) \n",
    "        ratio_A_average =np.average(r_line.ratio_A) \n",
    "        ratio_A_min=np.min(r_line.ratio_A)           \n",
    "        ratio_B_max =np.max(r_line.ratio_B) \n",
    "        ratio_B_average =np.average(r_line.ratio_B) \n",
    "        ratio_B_min=np.min(r_line.ratio_B)    \n",
    "        ratio_C_max =np.max(r_line.ratio_C) \n",
    "        ratio_C_average =np.average(r_line.ratio_C) \n",
    "        ratio_C_min=np.min(r_line.ratio_C) \n",
    "     \n",
    "        r_lane_center_pixels_recent_n_average  = np.average(r_line.lane_center_pixels_recent_n)\n",
    "        #print(r_lane_center_pixels_recent_n_average,'r_lane_center_pixels_recent_n_average')\n",
    "        r_diff = np.absolute(r_lane_center_pixels_recent_n_average - r_line.current_fit[2])        \n",
    "        #print (r_diff, 'r_diff ***')\n",
    "        #if(True):  \n",
    "        if ((l_line.diffs_l_r[0] < ( lt_d0)) and (l_line.diffs_l_r[0] > (gt_d0))) \\\n",
    "            and ((l_line.diffs_l_r[1] < ( lt_d1)) and (l_line.diffs_l_r[1] > (gt_d1))) \\\n",
    "            and ((r_line.ratio_B[-1] < ( lt_n1)) and (r_line.ratio_B[-1] > (-1.0*gt_n1))) \\\n",
    "            and (r_diff < ( lt_d3)) and (r_diff > (gt_d3)):\n",
    "            l_line.counter_7+=1\n",
    "            if (len(r_line.recent_fit) <n):\n",
    "                r_line.recent_fit.append(r_line.current_fit)\n",
    "                r_line.lane_center_pixels_recent_n.append(lane_center_pixels)\n",
    "                r_lane_center_pixels_recent_n_max =np.max(r_line.lane_center_pixels_recent_n)\n",
    "                r_lane_center_pixels_recent_n_average =np.average(r_line.lane_center_pixels_recent_n)\n",
    "                r_lane_center_pixels_recent_n_min=np.min(r_line.lane_center_pixels_recent_n)    \n",
    "                #print(r_lane_center_pixels_recent_n_max,'r_lane_center_pixels_recent_n_max')\n",
    "                #print(r_lane_center_pixels_recent_n_average,'r_lane_center_pixels_recent_n_average')\n",
    "                #print(r_lane_center_pixels_recent_n_min, 'r_lane_center_pixels_recent_n_min')  \n",
    "                r_line_diff_from_n_recent_center = np.absolute(r_lane_center_pixels_recent_n_average - r_line.current_fit[2])\n",
    "                #print(r_line_diff_from_n_recent_center,'r_line_diff_from_n_recent_center')\n",
    "                r_line.diff_from_center.append(r_line_diff_from_n_recent_center)\n",
    "                l_line.counter_8+=1\n",
    "            else:\n",
    "                r_line.recent_fit = r_line.recent_fit[1:]\n",
    "                r_line.recent_fit.append(r_line.current_fit)\n",
    "                r_line.lane_center_pixels_recent_n = r_line.lane_center_pixels_recent_n[1:]\n",
    "                r_line.lane_center_pixels_recent_n.append(lane_center_pixels)               \n",
    "                r_lane_center_pixels_recent_n_max =np.max(r_line.lane_center_pixels_recent_n)\n",
    "                r_lane_center_pixels_recent_n_average =np.average(r_line.lane_center_pixels_recent_n)\n",
    "                r_lane_center_pixels_recent_n_min=np.min(r_line.lane_center_pixels_recent_n)    \n",
    "                #print(r_lane_center_pixels_recent_n_max,'r_lane_center_pixels_recent_n_max')\n",
    "                #print(r_lane_center_pixels_recent_n_average,'r_lane_center_pixels_recent_n_average')\n",
    "                #print(r_lane_center_pixels_recent_n_min, 'r_lane_center_pixels_recent_n_min')  \n",
    "                r_line_diff_from_n_recent_center = np.absolute(r_lane_center_pixels_recent_n_average - r_line.current_fit[2])\n",
    "                #print(r_line_diff_from_n_recent_center,'r_line_diff_from_n_recent_center')\n",
    "                r_line.diff_from_center.append(r_line_diff_from_n_recent_center)                \n",
    "                l_line.counter_9+=1\n",
    "        else:    \n",
    "            l_line.counter_9a +=1\n",
    "    else:\n",
    "        r_line.recent_fit.append(r_line.current_fit)\n",
    "        r_line.lane_center_pixels_recent_n.append(lane_center_pixels)\n",
    "        r_lane_center_pixels_recent_n_max =np.max(r_line.lane_center_pixels_recent_n)\n",
    "        r_lane_center_pixels_recent_n_average =np.average(r_line.lane_center_pixels_recent_n)\n",
    "        r_lane_center_pixels_recent_n_min=np.min(r_line.lane_center_pixels_recent_n)     \n",
    "        r_line_diff_from_n_recent_center = np.absolute(r_lane_center_pixels_recent_n_average - r_line.current_fit[2])\n",
    "        r_line.diff_from_center.append(r_line_diff_from_n_recent_center)        \n",
    "        l_line.counter_10+=1  \n",
    "    \n",
    "    \n",
    "    #get the max, min, average of the A,B and C coefficients in the n recent fits from left_fit and  right_fit\n",
    "    #polynomial coefficients averaged over the last n iterations \n",
    "    #Get average to calulate best fit\n",
    "    l_line.best_fit =np.average(np.asarray(l_line.recent_fit), axis = 0)\n",
    "    r_line.best_fit =np.average(np.asarray(r_line.recent_fit), axis = 0) \n",
    "  \n",
    "\n",
    "    # 2-Define y-value where we want radius of curvature\n",
    "    #I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval_l = np.max(yvals_l)\n",
    "    y_eval_r = np.max(yvals_r)\n",
    "    left_curverad= ((1+(2*left_fit[0]*y_eval_l + left_fit[1])**2)**1.5)/np.absolute(2*left_fit[0])\n",
    "    #right_curverad= ((1+(2*right_fit[0]*y_eval + right_fit[1])**2)**1.5/np.absolute(2*right_fit[0])\n",
    "    right_curverad= ((1+(2*right_fit[0]*y_eval_r + right_fit[1])**2)**1.5)/np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, right_curverad)\n",
    "\n",
    "    # 3-Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "\n",
    "    left_fit_cr = np.polyfit(yvals_l*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(yvals_r*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval_l + left_fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval_r + right_fit_cr[1])**2)**1.5) \\\n",
    "                                    /np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm') \n",
    "    # Example values: 3380.7 m    3189.3 m\n",
    "    l_line.radius_of_curvature = left_curverad\n",
    "    r_line.radius_of_curvature = right_curverad\n",
    "\n",
    "    # 4-Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    #Method C plus best fit\n",
    "    yvals_l = np.linspace(25, 100, num=101)*7.2  # to cover same y-range as image\n",
    "    left_fitx = l_line.best_fit[0]*yvals_l**2 + l_line.best_fit[1]*yvals_l + l_line.best_fit[2]\n",
    "    yvals_r = np.linspace(25, 100, num=101)*7.2  # to cover same y-range as image\n",
    "    right_fitx = r_line.best_fit[0]*yvals_r**2 + r_line.best_fit[1]*yvals_r + r_line.best_fit[2]       \n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals_l]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals_r])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    #print(pts)\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp, Minv = birds_to_street(color_warp, src,dst)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    cv2.putText(result, str(\"Left Radius (meters)\"), (10,600), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, str(\"Right Radius (meters)\"), (900,600), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, str(\"Car Relative Position (meters)\"), (520,70), font, 1, (255,255,255), 2, cv2.LINE_AA)    \n",
    "    cv2.putText(result, str(l_line.radius_of_curvature), (10,650), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, str(r_line.radius_of_curvature), (1000,650), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, str(car_relative_position), (620,130), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Visual Display of the Lane Boundaries and Numerical Estimation of Lane Curvature and Vehicle Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    #print (image.shape)\n",
    "\n",
    "    #img_size = image.shape    \n",
    "    img_shape = image.shape  \n",
    "\n",
    "    img_size = (image.shape[1], image.shape[0]) \n",
    "    #print(img_size)\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = img_shape[1]\n",
    "    y_max = img_shape[0]\n",
    "\n",
    "    top_right = [x_max*0.585, y_max*0.64]\n",
    "    bottom_right = [x_max-0, y_max]\n",
    "    bottom_left = [x_min+55, y_max]\n",
    "    top_left = [x_max*0.425, y_max*0.64]\n",
    "    offset = 100 # offset for dst points\n",
    "    \n",
    "    src = np.float32([top_left, top_right, bottom_right, bottom_left])\n",
    "    dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "\n",
    "    #masking\n",
    "    vertices = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)\n",
    "\n",
    "    # 1-calibration runs one time \n",
    "    \n",
    "    # 2-correct distortion\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)  \n",
    "\n",
    "    # 3-color and gradient threshold\n",
    "    binary = pipeline(undist)\n",
    "\n",
    "    # vertices = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(binary, vertices)\n",
    "\n",
    "\n",
    "    # 4-transform\n",
    "    warped, M = birds_eye(masked_edges, src, dst)  \n",
    "\n",
    "    #All data in sliding windows is stored in l_line and r_line\n",
    "    sliding_window(warped, n=2) \n",
    "\n",
    "    result = pixels_to_image(warped, undist,src,dst,n=2)\n",
    "\n",
    "    #return binary\n",
    "    return result\n",
    "    #return warped, undist\n",
    "    #return warped, image\n",
    "    #return dstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1-calibration \n",
    "ret, mtx, dist, rvecs, tvecs =    calibrate_lens('camera_cal/calibration*.jpg', nx =9, ny =6) \n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "#Uncomment one of the following 3\n",
    "project_video = VideoFileClip('project_video.mp4')\n",
    "project_video_output = 'project_video_output.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "#challenge_video = VideoFileClip('challenge_video.mp4')\n",
    "#challenge_video_output = 'challenge_video_output.mp4'\n",
    "#clip = VideoFileClip(\"challenge_video.mp4\")\n",
    "\n",
    "#harder_challenge_video = VideoFileClip('harder_challenge_video.mp4')\n",
    "#harder_challenge_video_output = 'harder_challenge_video_output.mp4'\n",
    "#clip = VideoFileClip('harder_challenge_video.mp4')\n",
    "\n",
    "#Uncomment one of the following 3\n",
    "project_video_clip = clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_video_clip.write_videofile(project_video_output, audio=False)\n",
    "\n",
    "#project_video_clip = clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "#%time project_video_clip.write_videofile(challenge_video_output, audio=False)\n",
    "\n",
    "#project_video_clip = clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "#%time project_video_clip.write_videofile(harder_challenge_video_output, audio=False)\n",
    "\n",
    "#.format(project_video_output))\n",
    "#.format(challenge_video_output))\n",
    "#.format(harder_challenge_video_output))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an awesome topic. This was my first real implementation of a class that was useful. The notebook is designed to be a grand pipeline. So I can go back when time permits and improve and visualize the improvements as I go. Later I plan to try the challenges. I want to print out all RGB, and directional and magnitude gradients the way I did here with S channel. This will help me pick a better combination to create a binary image of the lanes. Also, I was thinking the vertices for the masking now is 4 points. If I could make the points in the vertices similar to the point in the lane lines of the previous image but slightly wider apart this would create a dynamic masking that closely mimics the previous images lane lines but father apart. Lastly I want to impliment a video for each stage of the prosses. So a video binary images or a video of the transformed, masked binary images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python3Environment]",
   "language": "python",
   "name": "Python [python3Environment]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
